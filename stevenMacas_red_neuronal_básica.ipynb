{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steven-Macas/PIA/blob/Red-Neuronal/stevenMacas_red_neuronal_b%C3%A1sica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4ndKMw9l272"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación de la red neuronal con retropropagación"
      ],
      "metadata": {
        "id": "GgxPYawHone4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetNode(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.inputs = []\n",
        "    self.weights = []\n",
        "    self.value = None"
      ],
      "metadata": {
        "id": "ayEcEwKcl_9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(object):\n",
        "\n",
        "  def __init__(self, layers, activation = \"relu\"):\n",
        "    self.net = [[NetNode() for _ in range(size)] for size in layers]\n",
        "    self.activation = activation #Elección de activación\n",
        "    sizes = len(layers)\n",
        "    for layer in range(1, sizes):\n",
        "        for node in self.net[layer]:\n",
        "            for unit in self.net[layer - 1]:\n",
        "                node.inputs.append(unit)\n",
        "                node.weights.append(0)\n",
        "\n",
        "  def accuracy(self, examples):\n",
        "    correct = 0\n",
        "    for x_test, y_test in examples:\n",
        "        prediction = self.predict(x_test)\n",
        "        if (y_test[prediction] == 1):\n",
        "            correct += 1\n",
        "    return correct / len(examples)\n",
        "\n",
        "  def backpropagation(self, eta, examples, epochs):\n",
        "    inputs = self.net[0]\n",
        "    outputs = self.net[-1]\n",
        "    layer_size = len(self.net)\n",
        "    for layer in self.net[1:]:\n",
        "        for node in layer:\n",
        "            node.weights = [np.random.uniform() for _ in range(len(node.weights))]\n",
        "    for epoch in range(epochs):\n",
        "        for x_train, y_train in examples:\n",
        "            for value, node in zip(x_train, inputs):\n",
        "                node.value = value\n",
        "            for layer in self.net[1:]:\n",
        "                for node in layer:\n",
        "                    in_val = [n.value for n in node.inputs]\n",
        "                    unit_value = np.dot(in_val, node.weights)\n",
        "                    #activation\n",
        "                    if self.activation == \"relu\":\n",
        "                      node.value = self.relu(unit_value)\n",
        "                    elif self.activation == \"sigmoide\":\n",
        "                      node.value = self.sigmoide(unit_value)\n",
        "            delta = [[] for _ in range(layer_size)]\n",
        "            err = [y_train[i] - outputs[i].value for i in range(len(outputs))]\n",
        "            #Elección de activación\n",
        "            if self.activation == \"relu\":\n",
        "              delta[-1] = [self.relu_prime(outputs[i].value) * err[i] for i in range(len(outputs))]\n",
        "            elif self.activation == \"sigmoide\":\n",
        "              delta[-1] = [self.sigmoide_prime(outputs[i].value) * err[i] for i in range(len(outputs))]\n",
        "            hidden_layers = layer_size - 2\n",
        "            for i in range(hidden_layers, 0, -1):\n",
        "                layer = self.net[i]\n",
        "                n_layers = len(layer)\n",
        "                w = [[node.weights[l] for node in self.net[i + 1]] for l in range(n_layers)]\n",
        "                #Elección de activción\n",
        "                if self.activation == \"relu\":\n",
        "                  delta[i] = [self.relu_prime(layer[j].value) * np.dot(w[j], delta[i + 1]) for j in range(n_layers)]\n",
        "                elif self.activation == \"sigmoide\":\n",
        "                  delta[i] = [self.sigmoide_prime(layer[j].value) * np.dot(w[j], delta[i + 1]) for j in range(n_layers)]\n",
        "            for i in range(1, layer_size):\n",
        "                layer = self.net[i]\n",
        "                in_val = [node.value for node in self.net[i - 1]]\n",
        "                n_layers = len(self.net[i])\n",
        "                for j in range(n_layers):\n",
        "                    layer[j].weights = np.add(layer[j].weights, np.multiply(eta * delta[i][j], in_val))\n",
        "        print(f\"epoch {epoch}/{epochs} | total error={np.sum(err)/len(examples)}\")\n",
        "  \n",
        "  def predict(self, input_data):\n",
        "    inputs = self.net[0]\n",
        "    for v, n in zip(input_data, inputs):\n",
        "        n.value = v\n",
        "    for layer in self.net[1:]:\n",
        "        for node in layer:\n",
        "            in_val = [n.value for n in node.inputs]\n",
        "            unit_value = np.dot(in_val, node.weights)\n",
        "            node.value = self.relu(unit_value)\n",
        "    outputs = self.net[-1]\n",
        "    return outputs.index(max(outputs, key=lambda node: node.value))\n",
        "\n",
        "  def relu(self, z):\n",
        "    return max(0, z)\n",
        "\n",
        "  def relu_prime(self, z):\n",
        "    return 1 if z > 0 else 0\n",
        "\n",
        "  def sigmoide(self, z):\n",
        "      return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "  def sigmoide_prime(self, z):\n",
        "      return self.sigmoide(z) * (1 - self.sigmoide(z))\n",
        "  \n",
        "  def set_weights(self, new_weights, new_biases):\n",
        "    self.weights = new_weights\n",
        "    self.biases = new_biases\n",
        "\n",
        "  def weights(self):\n",
        "    return [[[node.weights[i] for i in range(len(node.weights))] for node in layer] for layer in self.net]"
      ],
      "metadata": {
        "id": "c76uCuQsmC3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usando la red neuronal con un dataset"
      ],
      "metadata": {
        "id": "qgFoGWrqoyGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "fPng_kT1mhcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_X, iris_y = datasets.load_iris(return_X_y=True)"
      ],
      "metadata": {
        "id": "sFyU9RGtmluM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_x_normalized = normalize(iris_X, axis=0)"
      ],
      "metadata": {
        "id": "IQpaMM6Bmq1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(iris_x_normalized, iris_y, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "OjQkFVwmmuGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train, num_classes=3)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=3)"
      ],
      "metadata": {
        "id": "wvkyhxJTmyWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = []\n",
        "for i in range(len(X_train)):\n",
        "    examples.append([X_train[i], y_train[i]])"
      ],
      "metadata": {
        "id": "-ZlXfw4xm2Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network([4, 7, 3])\n",
        "net.backpropagation(0.1, examples, 500)"
      ],
      "metadata": {
        "id": "x9YqtPo7m5Vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e01610-3dc0-4920-ac00-ac029303b720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/500 | total error=-0.0025177957013839494\n",
            "epoch 1/500 | total error=-0.0020843343884047625\n",
            "epoch 2/500 | total error=-0.002034818619924651\n",
            "epoch 3/500 | total error=-0.0019993933170022052\n",
            "epoch 4/500 | total error=-0.0019357355525257303\n",
            "epoch 5/500 | total error=-0.0018497714661336122\n",
            "epoch 6/500 | total error=-0.0017298002559102328\n",
            "epoch 7/500 | total error=-0.0015744937469923633\n",
            "epoch 8/500 | total error=-0.0014048534169371731\n",
            "epoch 9/500 | total error=-0.0012084736408941542\n",
            "epoch 10/500 | total error=-0.0009296759351382457\n",
            "epoch 11/500 | total error=-0.0009794772682172714\n",
            "epoch 12/500 | total error=-0.0010520793535985968\n",
            "epoch 13/500 | total error=-0.0011033249174680234\n",
            "epoch 14/500 | total error=-0.0011531872988391112\n",
            "epoch 15/500 | total error=-0.0011996799858129182\n",
            "epoch 16/500 | total error=-0.001254104658163025\n",
            "epoch 17/500 | total error=-0.0013015520224873506\n",
            "epoch 18/500 | total error=-0.0013441137031622913\n",
            "epoch 19/500 | total error=-0.0013880270058002867\n",
            "epoch 20/500 | total error=-0.0014284661954307185\n",
            "epoch 21/500 | total error=-0.0014625039079480475\n",
            "epoch 22/500 | total error=-0.0014949434087167812\n",
            "epoch 23/500 | total error=-0.0015292920223087684\n",
            "epoch 24/500 | total error=-0.0015560128462339478\n",
            "epoch 25/500 | total error=-0.00158324632600657\n",
            "epoch 26/500 | total error=-0.0016130732686430375\n",
            "epoch 27/500 | total error=-0.0016331306289143804\n",
            "epoch 28/500 | total error=-0.0016541766891146966\n",
            "epoch 29/500 | total error=-0.0016738343140040044\n",
            "epoch 30/500 | total error=-0.0016928701194519784\n",
            "epoch 31/500 | total error=-0.0017115307577737211\n",
            "epoch 32/500 | total error=-0.0017262247078086378\n",
            "epoch 33/500 | total error=-0.0017388856565804449\n",
            "epoch 34/500 | total error=-0.0017525229323979768\n",
            "epoch 35/500 | total error=-0.0017626938765893303\n",
            "epoch 36/500 | total error=-0.0017725392493942568\n",
            "epoch 37/500 | total error=-0.0017813350057120831\n",
            "epoch 38/500 | total error=-0.0017891117118974324\n",
            "epoch 39/500 | total error=-0.0017961479684112038\n",
            "epoch 40/500 | total error=-0.0018022604253415699\n",
            "epoch 41/500 | total error=-0.0018068876751969887\n",
            "epoch 42/500 | total error=-0.0018123666336421868\n",
            "epoch 43/500 | total error=-0.0018174254801615539\n",
            "epoch 44/500 | total error=-0.0018219203722336836\n",
            "epoch 45/500 | total error=-0.0018263549008566045\n",
            "epoch 46/500 | total error=-0.0018305754775029474\n",
            "epoch 47/500 | total error=-0.0018341798624645059\n",
            "epoch 48/500 | total error=-0.0018377678686454994\n",
            "epoch 49/500 | total error=-0.0018408423728269517\n",
            "epoch 50/500 | total error=-0.0018437922999645908\n",
            "epoch 51/500 | total error=-0.001846456696350587\n",
            "epoch 52/500 | total error=-0.0018490780988647904\n",
            "epoch 53/500 | total error=-0.0018517001498807042\n",
            "epoch 54/500 | total error=-0.0018543127206828412\n",
            "epoch 55/500 | total error=-0.0018568814419264927\n",
            "epoch 56/500 | total error=-0.0018594163012018937\n",
            "epoch 57/500 | total error=-0.0018597260553884388\n",
            "epoch 58/500 | total error=-0.0018627254271939189\n",
            "epoch 59/500 | total error=-0.0018659706073058991\n",
            "epoch 60/500 | total error=-0.0018694208860242881\n",
            "epoch 61/500 | total error=-0.0018730445530894307\n",
            "epoch 62/500 | total error=-0.0018766339447555778\n",
            "epoch 63/500 | total error=-0.0018803530917396356\n",
            "epoch 64/500 | total error=-0.001884216100918947\n",
            "epoch 65/500 | total error=-0.0018882326439683729\n",
            "epoch 66/500 | total error=-0.001892408444955029\n",
            "epoch 67/500 | total error=-0.0018967465868104264\n",
            "epoch 68/500 | total error=-0.001901213344935609\n",
            "epoch 69/500 | total error=-0.0019056661555965303\n",
            "epoch 70/500 | total error=-0.0019103015509130687\n",
            "epoch 71/500 | total error=-0.0019154099472010629\n",
            "epoch 72/500 | total error=-0.0019206052884513\n",
            "epoch 73/500 | total error=-0.0019245958759521028\n",
            "epoch 74/500 | total error=-0.0019299909404649938\n",
            "epoch 75/500 | total error=-0.0019331504311918416\n",
            "epoch 76/500 | total error=-0.0019387793368826484\n",
            "epoch 77/500 | total error=-0.0019442810410128816\n",
            "epoch 78/500 | total error=-0.001949640168931931\n",
            "epoch 79/500 | total error=-0.00195489971167154\n",
            "epoch 80/500 | total error=-0.0019600169020886115\n",
            "epoch 81/500 | total error=-0.00196511884691128\n",
            "epoch 82/500 | total error=-0.001970065961172246\n",
            "epoch 83/500 | total error=-0.0019773554337460643\n",
            "epoch 84/500 | total error=-0.0019823863606648847\n",
            "epoch 85/500 | total error=-0.0020149587594715983\n",
            "epoch 86/500 | total error=-0.0020599360658881635\n",
            "epoch 87/500 | total error=-0.0021549584012609735\n",
            "epoch 88/500 | total error=-0.002207183797063075\n",
            "epoch 89/500 | total error=-0.0021568823795651676\n",
            "epoch 90/500 | total error=-0.0021201580466529524\n",
            "epoch 91/500 | total error=-0.00210795570556298\n",
            "epoch 92/500 | total error=-0.0020941686387106733\n",
            "epoch 93/500 | total error=-0.002080334342281298\n",
            "epoch 94/500 | total error=-0.002071188919057061\n",
            "epoch 95/500 | total error=-0.0020626310923850906\n",
            "epoch 96/500 | total error=-0.002057559456376366\n",
            "epoch 97/500 | total error=-0.002076979333607082\n",
            "epoch 98/500 | total error=-0.0020860969173905806\n",
            "epoch 99/500 | total error=-0.002137383919918594\n",
            "epoch 100/500 | total error=-0.002220519553901283\n",
            "epoch 101/500 | total error=-0.0022836845144718937\n",
            "epoch 102/500 | total error=-0.002228377316496194\n",
            "epoch 103/500 | total error=-0.002188057876946552\n",
            "epoch 104/500 | total error=-0.0021500495436958017\n",
            "epoch 105/500 | total error=-0.0021124833798974174\n",
            "epoch 106/500 | total error=-0.0021025399723348984\n",
            "epoch 107/500 | total error=-0.002064496836950392\n",
            "epoch 108/500 | total error=-0.002048015653520287\n",
            "epoch 109/500 | total error=-0.0020215818014587207\n",
            "epoch 110/500 | total error=-0.001991526887002464\n",
            "epoch 111/500 | total error=-0.0019631572400756582\n",
            "epoch 112/500 | total error=-0.0019487135532088177\n",
            "epoch 113/500 | total error=-0.0019169091316709787\n",
            "epoch 114/500 | total error=-0.0018925887868635582\n",
            "epoch 115/500 | total error=-0.0018645548660074414\n",
            "epoch 116/500 | total error=-0.0018291194160312922\n",
            "epoch 117/500 | total error=-0.0017837126125979958\n",
            "epoch 118/500 | total error=-0.0017271969089715012\n",
            "epoch 119/500 | total error=-0.0016940155700300625\n",
            "epoch 120/500 | total error=-0.0016541348216432457\n",
            "epoch 121/500 | total error=-0.0016049981950283807\n",
            "epoch 122/500 | total error=-0.0015514078369492017\n",
            "epoch 123/500 | total error=-0.001501989476157342\n",
            "epoch 124/500 | total error=-0.0014471526845994769\n",
            "epoch 125/500 | total error=-0.0013889859072551238\n",
            "epoch 126/500 | total error=-0.001338143417676029\n",
            "epoch 127/500 | total error=-0.0012886770959235072\n",
            "epoch 128/500 | total error=-0.001234198868023767\n",
            "epoch 129/500 | total error=-0.001191023432975182\n",
            "epoch 130/500 | total error=-0.0011556520190634837\n",
            "epoch 131/500 | total error=-0.0011029984908496613\n",
            "epoch 132/500 | total error=-0.001067427493457404\n",
            "epoch 133/500 | total error=-0.0010138056237419277\n",
            "epoch 134/500 | total error=-0.0009614481604437185\n",
            "epoch 135/500 | total error=-0.0009165820134379258\n",
            "epoch 136/500 | total error=-0.0008753177602713057\n",
            "epoch 137/500 | total error=-0.0008308937828444607\n",
            "epoch 138/500 | total error=-0.0007922038503447785\n",
            "epoch 139/500 | total error=-0.0007607245120613115\n",
            "epoch 140/500 | total error=-0.0007149128733742691\n",
            "epoch 141/500 | total error=-0.000677879650456296\n",
            "epoch 142/500 | total error=-0.0006391334374301292\n",
            "epoch 143/500 | total error=-0.0006057567041686936\n",
            "epoch 144/500 | total error=-0.0005668784363352182\n",
            "epoch 145/500 | total error=-0.000535113849306143\n",
            "epoch 146/500 | total error=-0.0005017387013891409\n",
            "epoch 147/500 | total error=-0.00045557295516933843\n",
            "epoch 148/500 | total error=-0.0004255104516777112\n",
            "epoch 149/500 | total error=-0.0003738163237409405\n",
            "epoch 150/500 | total error=-0.00034257192429962096\n",
            "epoch 151/500 | total error=-0.0003174257974538482\n",
            "epoch 152/500 | total error=-0.0002740529889800623\n",
            "epoch 153/500 | total error=-0.00023798421556115907\n",
            "epoch 154/500 | total error=-0.0001967152930016434\n",
            "epoch 155/500 | total error=-0.00016728964944232502\n",
            "epoch 156/500 | total error=-0.00013409423658856297\n",
            "epoch 157/500 | total error=-0.00010446082655810966\n",
            "epoch 158/500 | total error=-6.742868537386593e-05\n",
            "epoch 159/500 | total error=-3.979918174732977e-05\n",
            "epoch 160/500 | total error=-4.6370966151926265e-06\n",
            "epoch 161/500 | total error=1.6130106101856315e-05\n",
            "epoch 162/500 | total error=4.937491854035136e-05\n",
            "epoch 163/500 | total error=7.419886992279338e-05\n",
            "epoch 164/500 | total error=0.00010696584685978006\n",
            "epoch 165/500 | total error=0.0001287517980370717\n",
            "epoch 166/500 | total error=0.00016717610084118298\n",
            "epoch 167/500 | total error=0.00019584602357277842\n",
            "epoch 168/500 | total error=0.0002313807511288494\n",
            "epoch 169/500 | total error=0.0002533879526916462\n",
            "epoch 170/500 | total error=0.0002814871007197591\n",
            "epoch 171/500 | total error=0.0003036858259466026\n",
            "epoch 172/500 | total error=0.00033840071221163113\n",
            "epoch 173/500 | total error=0.0003454977565555212\n",
            "epoch 174/500 | total error=0.0003848738897235212\n",
            "epoch 175/500 | total error=0.0004110875193906146\n",
            "epoch 176/500 | total error=0.00042609406783699065\n",
            "epoch 177/500 | total error=0.00044893857711047667\n",
            "epoch 178/500 | total error=0.0004820973679538441\n",
            "epoch 179/500 | total error=0.0004985661177346843\n",
            "epoch 180/500 | total error=0.0004906274933692001\n",
            "epoch 181/500 | total error=0.0004829068911179559\n",
            "epoch 182/500 | total error=0.000479128076277476\n",
            "epoch 183/500 | total error=0.0004823661288255547\n",
            "epoch 184/500 | total error=0.00048244945277153286\n",
            "epoch 185/500 | total error=0.0004742739312594437\n",
            "epoch 186/500 | total error=0.0004750015699314612\n",
            "epoch 187/500 | total error=0.00047469060054619594\n",
            "epoch 188/500 | total error=0.0004743906624475538\n",
            "epoch 189/500 | total error=0.00046280610636114663\n",
            "epoch 190/500 | total error=0.00046583952709952083\n",
            "epoch 191/500 | total error=0.00046380297929118447\n",
            "epoch 192/500 | total error=0.0004554652594531148\n",
            "epoch 193/500 | total error=0.0004559267792011786\n",
            "epoch 194/500 | total error=0.00045547227900598987\n",
            "epoch 195/500 | total error=0.0004538737880017601\n",
            "epoch 196/500 | total error=0.00044457074619254355\n",
            "epoch 197/500 | total error=0.0004444001416812763\n",
            "epoch 198/500 | total error=0.000443503324306288\n",
            "epoch 199/500 | total error=0.00043452510737385466\n",
            "epoch 200/500 | total error=0.0004341528650252465\n",
            "epoch 201/500 | total error=0.00043327539674646495\n",
            "epoch 202/500 | total error=0.00042432233864380666\n",
            "epoch 203/500 | total error=0.00042416455209560354\n",
            "epoch 204/500 | total error=0.00042385084922428316\n",
            "epoch 205/500 | total error=0.00041612304030860987\n",
            "epoch 206/500 | total error=0.00041661221031885447\n",
            "epoch 207/500 | total error=0.000415909200831673\n",
            "epoch 208/500 | total error=0.00040690633022836636\n",
            "epoch 209/500 | total error=0.00040692260169330476\n",
            "epoch 210/500 | total error=0.0004060636745314539\n",
            "epoch 211/500 | total error=0.000389975547478034\n",
            "epoch 212/500 | total error=0.00037530371844445297\n",
            "epoch 213/500 | total error=0.00037245999116741757\n",
            "epoch 214/500 | total error=0.0003512142022738215\n",
            "epoch 215/500 | total error=0.0003222871893879986\n",
            "epoch 216/500 | total error=0.0003415385250002262\n",
            "epoch 217/500 | total error=0.0003457054996813758\n",
            "epoch 218/500 | total error=0.00034660760031910245\n",
            "epoch 219/500 | total error=0.000350283545722598\n",
            "epoch 220/500 | total error=0.0003448272519833484\n",
            "epoch 221/500 | total error=0.00034281857640306075\n",
            "epoch 222/500 | total error=0.00034239704480493\n",
            "epoch 223/500 | total error=0.0003403702937901117\n",
            "epoch 224/500 | total error=0.0003386669907245038\n",
            "epoch 225/500 | total error=0.00033577301297000315\n",
            "epoch 226/500 | total error=0.00033562009184106195\n",
            "epoch 227/500 | total error=0.00033298249378975556\n",
            "epoch 228/500 | total error=0.00033303267007277665\n",
            "epoch 229/500 | total error=0.00033127367987969186\n",
            "epoch 230/500 | total error=0.0003272256733773136\n",
            "epoch 231/500 | total error=0.0003262072697948491\n",
            "epoch 232/500 | total error=0.0003245240078662059\n",
            "epoch 233/500 | total error=0.00032168917823126954\n",
            "epoch 234/500 | total error=0.0003200861331176243\n",
            "epoch 235/500 | total error=0.00031901286324247194\n",
            "epoch 236/500 | total error=0.00031596327119676193\n",
            "epoch 237/500 | total error=0.0003151842116658856\n",
            "epoch 238/500 | total error=0.0003121894555007887\n",
            "epoch 239/500 | total error=0.0003114733847623933\n",
            "epoch 240/500 | total error=0.000308447767121454\n",
            "epoch 241/500 | total error=0.00030777191879915083\n",
            "epoch 242/500 | total error=0.0003102841107904616\n",
            "epoch 243/500 | total error=0.00030505607336143157\n",
            "epoch 244/500 | total error=0.0003032926052931502\n",
            "epoch 245/500 | total error=0.0002998334909289931\n",
            "epoch 246/500 | total error=0.0002989491689371968\n",
            "epoch 247/500 | total error=0.00029580339768990144\n",
            "epoch 248/500 | total error=0.00029406569302746857\n",
            "epoch 249/500 | total error=0.000292427940436768\n",
            "epoch 250/500 | total error=0.00029049509933889626\n",
            "epoch 251/500 | total error=0.0002887575904699217\n",
            "epoch 252/500 | total error=0.00028685662309693624\n",
            "epoch 253/500 | total error=0.00028508145805880754\n",
            "epoch 254/500 | total error=0.0002832423327657226\n",
            "epoch 255/500 | total error=0.0002814227439321896\n",
            "epoch 256/500 | total error=0.0002796549673037626\n",
            "epoch 257/500 | total error=0.0002766821736788929\n",
            "epoch 258/500 | total error=0.0002763440428753927\n",
            "epoch 259/500 | total error=0.0002742112918605664\n",
            "epoch 260/500 | total error=0.00027246141339279384\n",
            "epoch 261/500 | total error=0.0002694123847124086\n",
            "epoch 262/500 | total error=0.00026917080115381186\n",
            "epoch 263/500 | total error=0.00026586543539035924\n",
            "epoch 264/500 | total error=0.00026541655698578506\n",
            "epoch 265/500 | total error=0.00026202483555351025\n",
            "epoch 266/500 | total error=0.000261705924039161\n",
            "epoch 267/500 | total error=0.000258363238859675\n",
            "epoch 268/500 | total error=0.0002565561963492511\n",
            "epoch 269/500 | total error=0.00025448098965252244\n",
            "epoch 270/500 | total error=0.0002530281929554327\n",
            "epoch 271/500 | total error=0.00024938341015867487\n",
            "epoch 272/500 | total error=0.00025090437876158685\n",
            "epoch 273/500 | total error=0.0002462519511496212\n",
            "epoch 274/500 | total error=0.00024757771471800767\n",
            "epoch 275/500 | total error=0.0002428978275684566\n",
            "epoch 276/500 | total error=0.00024112148228113046\n",
            "epoch 277/500 | total error=0.00023856301692513164\n",
            "epoch 278/500 | total error=0.00024046338950418726\n",
            "epoch 279/500 | total error=0.00023511409077041264\n",
            "epoch 280/500 | total error=0.00023511049423398841\n",
            "epoch 281/500 | total error=0.00023199614590532953\n",
            "epoch 282/500 | total error=0.00023038769593145363\n",
            "epoch 283/500 | total error=0.00022808048892842178\n",
            "epoch 284/500 | total error=0.0002298456395247367\n",
            "epoch 285/500 | total error=0.00022114833233912907\n",
            "epoch 286/500 | total error=0.0002148753580772859\n",
            "epoch 287/500 | total error=0.00020899829343100178\n",
            "epoch 288/500 | total error=0.00020680147336335868\n",
            "epoch 289/500 | total error=0.00021205053468465184\n",
            "epoch 290/500 | total error=0.00020665899967677593\n",
            "epoch 291/500 | total error=0.0002043938501003521\n",
            "epoch 292/500 | total error=0.0002015078068423622\n",
            "epoch 293/500 | total error=0.00020196003538108058\n",
            "epoch 294/500 | total error=0.00019947391202179422\n",
            "epoch 295/500 | total error=0.00019880542051404492\n",
            "epoch 296/500 | total error=0.00019695797988125707\n",
            "epoch 297/500 | total error=0.00019758566507903827\n",
            "epoch 298/500 | total error=0.00019381530918970806\n",
            "epoch 299/500 | total error=0.0001945609490707323\n",
            "epoch 300/500 | total error=0.00020057004235299788\n",
            "epoch 301/500 | total error=0.00019311160577868136\n",
            "epoch 302/500 | total error=0.00019195543767354476\n",
            "epoch 303/500 | total error=0.00018965518177237276\n",
            "epoch 304/500 | total error=0.00018799684260449313\n",
            "epoch 305/500 | total error=0.00018445628298676778\n",
            "epoch 306/500 | total error=0.00018445180501872974\n",
            "epoch 307/500 | total error=0.00018940839709767713\n",
            "epoch 308/500 | total error=0.00018100502978156408\n",
            "epoch 309/500 | total error=0.00018122376324615773\n",
            "epoch 310/500 | total error=0.0001780950101436122\n",
            "epoch 311/500 | total error=0.00017684123877775572\n",
            "epoch 312/500 | total error=0.00017378387865014667\n",
            "epoch 313/500 | total error=0.00017072336326633407\n",
            "epoch 314/500 | total error=0.00017347444909956248\n",
            "epoch 315/500 | total error=0.00017715266009010744\n",
            "epoch 316/500 | total error=0.00016956439746391161\n",
            "epoch 317/500 | total error=0.00016991854136313433\n",
            "epoch 318/500 | total error=0.00016296414513647476\n",
            "epoch 319/500 | total error=0.00016529597126177149\n",
            "epoch 320/500 | total error=0.0001680001199237576\n",
            "epoch 321/500 | total error=0.00016281886903067773\n",
            "epoch 322/500 | total error=0.00016035573491527956\n",
            "epoch 323/500 | total error=0.0001579795198698238\n",
            "epoch 324/500 | total error=0.0001572867000555182\n",
            "epoch 325/500 | total error=0.00015410832252353291\n",
            "epoch 326/500 | total error=0.00015134107644653266\n",
            "epoch 327/500 | total error=0.00015315441265777163\n",
            "epoch 328/500 | total error=0.00015564751133898547\n",
            "epoch 329/500 | total error=0.0001505735181468515\n",
            "epoch 330/500 | total error=0.0001489673245915285\n",
            "epoch 331/500 | total error=0.00014530378744093502\n",
            "epoch 332/500 | total error=0.00014237956290945504\n",
            "epoch 333/500 | total error=0.0001442244016454412\n",
            "epoch 334/500 | total error=0.0001466914691961696\n",
            "epoch 335/500 | total error=0.00014157509047181733\n",
            "epoch 336/500 | total error=0.0001388775473421681\n",
            "epoch 337/500 | total error=0.0001364398254383642\n",
            "epoch 338/500 | total error=0.0001346445444866673\n",
            "epoch 339/500 | total error=0.00014069132565887785\n",
            "epoch 340/500 | total error=0.00013356043051135913\n",
            "epoch 341/500 | total error=0.00013163477121262238\n",
            "epoch 342/500 | total error=0.0001285620263269005\n",
            "epoch 343/500 | total error=0.00012586405001383064\n",
            "epoch 344/500 | total error=0.00012667663008299282\n",
            "epoch 345/500 | total error=0.00013167789718926867\n",
            "epoch 346/500 | total error=0.00012468394894977938\n",
            "epoch 347/500 | total error=0.00012285308339385624\n",
            "epoch 348/500 | total error=0.00011987062622518345\n",
            "epoch 349/500 | total error=0.0001171893930984269\n",
            "epoch 350/500 | total error=0.00011241603955382354\n",
            "epoch 351/500 | total error=0.00011074581930514971\n",
            "epoch 352/500 | total error=0.0001125100473322029\n",
            "epoch 353/500 | total error=0.00011081426282595527\n",
            "epoch 354/500 | total error=0.00011017773945133739\n",
            "epoch 355/500 | total error=0.000115474847400913\n",
            "epoch 356/500 | total error=0.00010971392097958536\n",
            "epoch 357/500 | total error=0.00010764282806254208\n",
            "epoch 358/500 | total error=0.0001041162898502146\n",
            "epoch 359/500 | total error=9.823904244320077e-05\n",
            "epoch 360/500 | total error=9.705998437138374e-05\n",
            "epoch 361/500 | total error=9.91240956680665e-05\n",
            "epoch 362/500 | total error=9.62079656591582e-05\n",
            "epoch 363/500 | total error=9.694287033971404e-05\n",
            "epoch 364/500 | total error=0.00010300688289145248\n",
            "epoch 365/500 | total error=9.490763918246677e-05\n",
            "epoch 366/500 | total error=8.938381448405734e-05\n",
            "epoch 367/500 | total error=8.742881436458738e-05\n",
            "epoch 368/500 | total error=8.259760316478663e-05\n",
            "epoch 369/500 | total error=7.859486638407965e-05\n",
            "epoch 370/500 | total error=7.94294771957138e-05\n",
            "epoch 371/500 | total error=8.433770409480475e-05\n",
            "epoch 372/500 | total error=7.925746381794255e-05\n",
            "epoch 373/500 | total error=7.7928954881142e-05\n",
            "epoch 374/500 | total error=8.595611834612549e-05\n",
            "epoch 375/500 | total error=7.933037605685756e-05\n",
            "epoch 376/500 | total error=7.896501246151821e-05\n",
            "epoch 377/500 | total error=7.493518698875971e-05\n",
            "epoch 378/500 | total error=6.970280343794414e-05\n",
            "epoch 379/500 | total error=6.871925106767262e-05\n",
            "epoch 380/500 | total error=7.101343928092493e-05\n",
            "epoch 381/500 | total error=6.812435743657382e-05\n",
            "epoch 382/500 | total error=6.187771062366639e-05\n",
            "epoch 383/500 | total error=6.580527829878243e-05\n",
            "epoch 384/500 | total error=6.344089619979102e-05\n",
            "epoch 385/500 | total error=6.476447508652987e-05\n",
            "epoch 386/500 | total error=6.97568315396672e-05\n",
            "epoch 387/500 | total error=6.068635363421874e-05\n",
            "epoch 388/500 | total error=6.219471083002877e-05\n",
            "epoch 389/500 | total error=6.683948374239801e-05\n",
            "epoch 390/500 | total error=5.752031851083602e-05\n",
            "epoch 391/500 | total error=5.341909120492501e-05\n",
            "epoch 392/500 | total error=5.093306149085245e-05\n",
            "epoch 393/500 | total error=5.4884952026488613e-05\n",
            "epoch 394/500 | total error=4.923959003667044e-05\n",
            "epoch 395/500 | total error=4.654795573579562e-05\n",
            "epoch 396/500 | total error=4.246837248153094e-05\n",
            "epoch 397/500 | total error=4.8479404350190715e-05\n",
            "epoch 398/500 | total error=5.1808254683424757e-05\n",
            "epoch 399/500 | total error=4.708746758094092e-05\n",
            "epoch 400/500 | total error=4.737550487903808e-05\n",
            "epoch 401/500 | total error=4.9382073201780415e-05\n",
            "epoch 402/500 | total error=4.177809345943436e-05\n",
            "epoch 403/500 | total error=3.7079410807212367e-05\n",
            "epoch 404/500 | total error=3.7277605213079104e-05\n",
            "epoch 405/500 | total error=3.7307226572055876e-05\n",
            "epoch 406/500 | total error=3.468933399705017e-05\n",
            "epoch 407/500 | total error=3.207353266971857e-05\n",
            "epoch 408/500 | total error=2.762247548688997e-05\n",
            "epoch 409/500 | total error=3.3530099711278255e-05\n",
            "epoch 410/500 | total error=3.6787071810297684e-05\n",
            "epoch 411/500 | total error=2.9669997409912756e-05\n",
            "epoch 412/500 | total error=2.223718422085519e-05\n",
            "epoch 413/500 | total error=1.9874388923573258e-05\n",
            "epoch 414/500 | total error=2.2994195456290296e-05\n",
            "epoch 415/500 | total error=2.766947030161763e-05\n",
            "epoch 416/500 | total error=2.046292749205795e-05\n",
            "epoch 417/500 | total error=1.6119310913225344e-05\n",
            "epoch 418/500 | total error=2.342660991340358e-05\n",
            "epoch 419/500 | total error=1.9303301072033188e-05\n",
            "epoch 420/500 | total error=1.1949647562807993e-05\n",
            "epoch 421/500 | total error=1.3398644135147648e-05\n",
            "epoch 422/500 | total error=1.7317880501763193e-05\n",
            "epoch 423/500 | total error=1.6392438039133003e-05\n",
            "epoch 424/500 | total error=1.0874965451563672e-05\n",
            "epoch 425/500 | total error=1.3760866142790521e-05\n",
            "epoch 426/500 | total error=1.4882436616664441e-05\n",
            "epoch 427/500 | total error=7.666824844910584e-06\n",
            "epoch 428/500 | total error=1.0635445179666784e-05\n",
            "epoch 429/500 | total error=1.1765930683010906e-05\n",
            "epoch 430/500 | total error=3.2686188473092977e-06\n",
            "epoch 431/500 | total error=8.649927538968242e-06\n",
            "epoch 432/500 | total error=-1.2471778405002502e-06\n",
            "epoch 433/500 | total error=4.952449655614329e-06\n",
            "epoch 434/500 | total error=6.941392304083786e-06\n",
            "epoch 435/500 | total error=-7.161427472146542e-08\n",
            "epoch 436/500 | total error=2.0222433528542065e-06\n",
            "epoch 437/500 | total error=2.576670870702939e-06\n",
            "epoch 438/500 | total error=-5.966698702838021e-06\n",
            "epoch 439/500 | total error=1.0463647086937182e-06\n",
            "epoch 440/500 | total error=5.160823156685756e-07\n",
            "epoch 441/500 | total error=-7.557210952154521e-07\n",
            "epoch 442/500 | total error=-6.745096499192564e-06\n",
            "epoch 443/500 | total error=-8.9225686372707e-07\n",
            "epoch 444/500 | total error=-4.467960881397263e-06\n",
            "epoch 445/500 | total error=-1.0769940699129066e-05\n",
            "epoch 446/500 | total error=-3.7572436832592852e-06\n",
            "epoch 447/500 | total error=-1.7747056884139431e-06\n",
            "epoch 448/500 | total error=-9.415831184219255e-06\n",
            "epoch 449/500 | total error=-8.351753413412174e-06\n",
            "epoch 450/500 | total error=-1.8271803526844395e-05\n",
            "epoch 451/500 | total error=-1.5825129928361454e-05\n",
            "epoch 452/500 | total error=-1.5844575189353598e-05\n",
            "epoch 453/500 | total error=-2.3060312953047482e-05\n",
            "epoch 454/500 | total error=-1.5026605535180722e-05\n",
            "epoch 455/500 | total error=-1.6582746639496698e-05\n",
            "epoch 456/500 | total error=-1.5604023915603376e-05\n",
            "epoch 457/500 | total error=-2.4512282865313263e-05\n",
            "epoch 458/500 | total error=-2.327744983361043e-05\n",
            "epoch 459/500 | total error=-1.760476778184435e-05\n",
            "epoch 460/500 | total error=-1.3865859343200245e-05\n",
            "epoch 461/500 | total error=-2.332871299374206e-05\n",
            "epoch 462/500 | total error=-1.8326461006927067e-05\n",
            "epoch 463/500 | total error=-2.866481525902742e-05\n",
            "epoch 464/500 | total error=-2.8094930350160605e-05\n",
            "epoch 465/500 | total error=-3.052635960013409e-05\n",
            "epoch 466/500 | total error=-3.2042613825293094e-05\n",
            "epoch 467/500 | total error=-2.7672561608630777e-05\n",
            "epoch 468/500 | total error=-2.9173616891649732e-05\n",
            "epoch 469/500 | total error=-3.1948108755556576e-05\n",
            "epoch 470/500 | total error=-3.318667716668555e-05\n",
            "epoch 471/500 | total error=-3.8956064048874715e-05\n",
            "epoch 472/500 | total error=-2.953047593209357e-05\n",
            "epoch 473/500 | total error=-3.712065683561712e-05\n",
            "epoch 474/500 | total error=-3.290563033834977e-05\n",
            "epoch 475/500 | total error=-4.2486646493866687e-05\n",
            "epoch 476/500 | total error=-3.8424949084416475e-05\n",
            "epoch 477/500 | total error=-3.497986094754084e-05\n",
            "epoch 478/500 | total error=-3.252590406120174e-05\n",
            "epoch 479/500 | total error=-3.2775328817428544e-05\n",
            "epoch 480/500 | total error=-3.976352123495897e-05\n",
            "epoch 481/500 | total error=-4.1996286463634e-05\n",
            "epoch 482/500 | total error=-4.401886180186998e-05\n",
            "epoch 483/500 | total error=-4.982204409598734e-05\n",
            "epoch 484/500 | total error=-4.0603744457701205e-05\n",
            "epoch 485/500 | total error=-4.8292375730141225e-05\n",
            "epoch 486/500 | total error=-4.761301246222575e-05\n",
            "epoch 487/500 | total error=-5.0996776318508925e-05\n",
            "epoch 488/500 | total error=-5.2794666846767146e-05\n",
            "epoch 489/500 | total error=-4.752385360223821e-05\n",
            "epoch 490/500 | total error=-5.272743393886318e-05\n",
            "epoch 491/500 | total error=-5.039984822863275e-05\n",
            "epoch 492/500 | total error=-4.883325692184859e-05\n",
            "epoch 493/500 | total error=-4.4811050141913e-05\n",
            "epoch 494/500 | total error=-5.362512851495952e-05\n",
            "epoch 495/500 | total error=-5.475425872924859e-05\n",
            "epoch 496/500 | total error=-4.906699018886925e-05\n",
            "epoch 497/500 | total error=-4.799308186247594e-05\n",
            "epoch 498/500 | total error=-4.908052719611959e-05\n",
            "epoch 499/500 | total error=-5.823503326446063e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#precisión alcanzada con los datos de entrenamiento\n",
        "accuracy = net.accuracy(examples)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "FLxCnkvMm9Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e74381d-b190-49d7-c993-edf394b18205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#precisión alcanzada con los datos de prueba\n",
        "examples = []\n",
        "for i in range(len(X_test)):\n",
        "    examples.append([X_test[i], y_test[i]])\n",
        "accuracy = net.accuracy(examples)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "35AyCvCmm_96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495bb26a-2569-425a-c3fb-f056c8045af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#probando con un dato\n",
        "prediction = net.predict(X_test[2])\n",
        "print(f\"Desired output: {y_test[2]}\")\n",
        "print(f\"Index of output: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGMT3cV2ocL2",
        "outputId": "6f8021ea-4978-4b4e-d7f7-6bc00c722cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desired output: [1. 0. 0.]\n",
            "Index of output: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modificación de la implementación de la red neuronal"
      ],
      "metadata": {
        "id": "M8-mcDfFprEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# agrega el método weigths() a la clase Network, de tal forma que permita obtener los pesos de las neuronas\n",
        "def weights(self):\n",
        "    return [[[node.weights[i] for i in range(len(node.weights))] for node in layer] for layer in self.net]\n",
        "# agrega el método set_weights() a la clase Network, de tal forma que permite definir los pesos de las neuronas\n",
        "def set_weights(self, new_weights, new_biases):\n",
        "    self.weights = new_weights\n",
        "    self.biases = new_biases"
      ],
      "metadata": {
        "id": "uKEBVbXPp09D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agrega los métodos sigmoide() y sigmoide_prime() a la clase Network\n",
        "def sigmoide(self, z):\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "def sigmoide_prime(self, z):\n",
        "    return self.sigmoide(z) * (1 - self.sigmoide(z))\n",
        "\n",
        "# modifica la clase Network, para que se pueda decidir qué función de activación utilizar: relu() o sigmoide()\n",
        "#Línea 5,36,43,53"
      ],
      "metadata": {
        "id": "Yg3ScNjfq_ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los métodos predict() y accuracy() de la clase Network están implementados para resolver problemas de clasificación\n",
        "\n",
        "# modifícalos de tal manera que también se puedan utilizar con problemas de regresión\n",
        "class Network(object):\n",
        "\n",
        "  def __init__(self, layers, activation = \"relu\"):\n",
        "    self.net = [[NetNode() for _ in range(size)] for size in layers]\n",
        "    self.activation = activation #Elección de activación\n",
        "    sizes = len(layers)\n",
        "    for layer in range(1, sizes):\n",
        "        for node in self.net[layer]:\n",
        "            for unit in self.net[layer - 1]:\n",
        "                node.inputs.append(unit)\n",
        "                node.weights.append(0)\n",
        "\n",
        "  def accuracy(self, examples):\n",
        "    total_error = 0\n",
        "    for x_test, y_test in examples:\n",
        "      prediction = self.predict(x_test)\n",
        "      total_error += sum((y_test[i] - prediction[i])**2 for i in range(len(prediction)))\n",
        "    return 1 - (total_error / len(examples))\n",
        "\n",
        "  def backpropagation(self, eta, examples, epochs):\n",
        "    inputs = self.net[0]\n",
        "    outputs = self.net[-1]\n",
        "    layer_size = len(self.net)\n",
        "    for layer in self.net[1:]:\n",
        "        for node in layer:\n",
        "            node.weights = [np.random.uniform() for _ in range(len(node.weights))]\n",
        "    node_values = [] #Almacenamos los valores de los nodos en cada capa para cada ejemplo\n",
        "    for epoch in range(epochs):\n",
        "        for x_train, y_train in examples:\n",
        "            for value, node in zip(x_train, inputs):\n",
        "                node.value = value\n",
        "            for layer in self.net[1:]:\n",
        "                for node in layer:\n",
        "                    in_val = [n.value for n in node.inputs]\n",
        "                    unit_value = np.dot(in_val, node.weights)\n",
        "                    #activation\n",
        "                    if self.activation == \"relu\":\n",
        "                      node.value = self.relu(unit_value)\n",
        "                    elif self.activation == \"sigmoide\":\n",
        "                      node.value = self.sigmoide(unit_value)\n",
        "            node_values.append([node.value for layer in self.net for node in layer]) # agregar valores de nodos actuales\n",
        "            delta = [[] for _ in range(layer_size)]\n",
        "            err = [y_train[i] - outputs[i].value for i in range(len(outputs))]\n",
        "            #Elección de activación\n",
        "            if self.activation == \"relu\":\n",
        "              delta[-1] = [self.relu_prime(outputs[i].value) * err[i] for i in range(len(outputs))]\n",
        "            elif self.activation == \"sigmoide\":\n",
        "              delta[-1] = [self.sigmoide_prime(outputs[i].value) * err[i] for i in range(len(outputs))]\n",
        "            hidden_layers = layer_size - 2\n",
        "            for i in range(hidden_layers, 0, -1):\n",
        "                layer = self.net[i]\n",
        "                n_layers = len(layer)\n",
        "                w = [[node.weights[l] for node in self.net[i + 1]] for l in range(n_layers)]\n",
        "                #Elección de activción\n",
        "                if self.activation == \"relu\":\n",
        "                  delta[i] = [self.relu_prime(layer[j].value) * np.dot(w[j], delta[i + 1]) for j in range(n_layers)]\n",
        "                elif self.activation == \"sigmoide\":\n",
        "                  delta[i] = [self.sigmoide_prime(layer[j].value) * np.dot(w[j], delta[i + 1]) for j in range(n_layers)]\n",
        "            for i in range(1, layer_size):\n",
        "                layer = self.net[i]\n",
        "                in_val = [node.value for node in self.net[i - 1]]\n",
        "                n_layers = len(self.net[i])\n",
        "                for j in range(n_layers):\n",
        "                    layer[j].weights = np.add(layer[j].weights, np.multiply(eta * delta[i][j], in_val))\n",
        "        print(f\"epoch {epoch}/{epochs} | total error={np.sum(err)/len(examples)}\")\n",
        "    return np.array(node_values)\n",
        "  \n",
        "  def predict(self, input_data):\n",
        "    inputs = self.net[0]\n",
        "    for v, n in zip(input_data, inputs):\n",
        "        n.value = v\n",
        "    for layer in self.net[1:]:\n",
        "        for node in layer:\n",
        "            in_val = [n.value for n in node.inputs]\n",
        "            unit_value = np.dot(in_val, node.weights)\n",
        "            node.value = self.relu(unit_value) if self.activation_func == 'relu' else self.sigmoide(unit_value)\n",
        "    outputs = self.net[-1]\n",
        "    return outputs[0].value\n",
        "\n",
        "  def relu(self, z):\n",
        "    return max(0, z)\n",
        "\n",
        "  def relu_prime(self, z):\n",
        "    return 1 if z > 0 else 0\n",
        "\n",
        "  def sigmoide(self, z):\n",
        "      return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "  def sigmoide_prime(self, z):\n",
        "      return self.sigmoide(z) * (1 - self.sigmoide(z))\n",
        "  \n",
        "  def set_weights(self, new_weights, new_biases):\n",
        "    self.weights = new_weights\n",
        "    self.biases = new_biases\n",
        "\n",
        "  def weights(self):\n",
        "    return [[[node.weights[i] for i in range(len(node.weights))] for node in layer] for layer in self.net]"
      ],
      "metadata": {
        "id": "XUYfTnwwtAP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modifica el método backpropagation() de tal manera que devuelva como resultado el array de valores de los nodos durante las épocas de entrenamiento\n",
        "#Linea 30,44,69"
      ],
      "metadata": {
        "id": "_jcNyPgK0Jdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# una vez implementados los cambios, entrena la red neuronal del ejemplo de los apuntes\n",
        "examples = []\n",
        "examples.append([[0.5, 0.67, 0.5], [0.25, 0.6]])"
      ],
      "metadata": {
        "id": "ROQGXdl8uNXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecuta la red neuronal para los datos de ejemplo de los apuntes\n",
        "# comprueba los valores de los nodos y de los pesos\n",
        "# los valores de los nodos tienen que ser los mismos que los de los apuntes\n",
        "# los valores de los pesos son ligeramente diferentes, ¿por qué?\n",
        "\n",
        "net = Network([3, 4, 2])\n",
        "\n",
        "net.set_weights([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
        "# o\n",
        "net.set_weights([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3], [0.4, 0.4, 0.4], [0.5, 0.5, 0.5, 0.5], [0.6, 0.6, 0.6, 0.6]])\n",
        "\n",
        "valores_nodos = net.backpropagation(0.9, examples, 1)\n",
        "\n",
        "print(valores_nodos)\n",
        "net.weights()"
      ],
      "metadata": {
        "id": "Q-0NYrsYu2nH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}